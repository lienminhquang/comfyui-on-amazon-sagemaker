FROM pytorch/pytorch:2.0.1-cuda11.7-cudnn8-runtime


ENV TZ=Europe/Minsk
# Allow statements and log messages to immediately appear in the Knative logs
ENV PYTHONUNBUFFERED True
ENV DEBIAN_FRONTEND=noninteractive

RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone

RUN apt-get update && \
        apt-get install --no-install-recommends ffmpeg libsm6 libxext6  -y && \
        apt-get clean && \
        git \
        curl \
        nginx \
        rm -rf /var/lib/apt/lists/*


# Set some environment variables. PYTHONUNBUFFERED prevents Python buffering our standard
# output stream, which means that logs can be delivered to the user quickly. PYTHONDONTWRITEBYTECODE
# stops Python creating the .pyc files which are unnecessary in this case.
ENV PYTHONUNBUFFERED=TRUE
ENV PYTHONDONTWRITEBYTECODE=TRUE

# Git reference of ComfyUI (can be a branch name or commit id)
ARG COMFYUI_GIT_REF=6d281b4ff4ad3918a4f3b4ca4a8b547a2ba3bf80

WORKDIR /opt/program

# Install ComfyUI
RUN git clone https://github.com/comfyanonymous/ComfyUI.git && \
    cd /opt/program/ComfyUI && \
    git checkout $COMFYUI_GIT_REF
# RUN pip3 install --no-cache-dir -r /opt/program/ComfyUI/requirements.txt


# Copy extra_model_paths so that ComfyUI load the model artifacts
COPY extra_model_paths.yaml /opt/program/ComfyUI/

# Copy contents of code/ dir to /opt/program
COPY code/ /opt/program/
RUN pip3 install --no-cache-dir -r /opt/program/comfy-requirements.txt
RUN pip3 install --no-cache-dir -r /opt/program/requirements.txt

#checkov:skip=CKV_DOCKER_3:SageMaker expects all containers to run with root users

RUN pip install --no-cache-dir -r requirements.txt \
    && rm -rf /root/.cache/pip && \
    pip install --no-cache-dir mmcv==2.0.1 -f https://download.openmmlab.com/mmcv/dist/cu117/torch2.0/index.html && \
    pip uninstall -y opencv-python opencv-contrib-python opencv-python-headless opencv-contrib-python-headless && \
    pip install --no-cache-dir --disable-pip-version-check opencv-contrib-python==4.7.0.72 && \
    pip install llama-cpp-python --prefer-binary --extra-index-url=https://jllllll.github.io/llama-cpp-python-cuBLAS-wheels/AVX2/cu117

# Clone and checkout ComfyUI-Impact-Pack
RUN git clone https://github.com/lienminhquang/ComfyUI-Impact-Pack.git /opt/program/ComfyUI/custom_nodes/ComfyUI-Impact-Pack && \
    cd /opt/program/ComfyUI/custom_nodes/ComfyUI-Impact-Pack && \
    git checkout 869a43f00ed6c3867a7cdd0d8a8a2ebe75b9b5a3

# Clone and checkout ComfyUI-Allor
RUN git clone https://github.com/Nourepide/ComfyUI-Allor.git /opt/program/ComfyUI/custom_nodes/ComfyUI-Allor && \
    cd /opt/program/ComfyUI/custom_nodes/ComfyUI-Allor && \
    git checkout b7fb9ff0bd50124afcbf8cd2638a73f883d32a23


# Initialize custom nodes
RUN echo "########################################" && \
    echo "Init ComfyUI-Impact-Pack..." && \
    cd /opt/program/ComfyUI/custom_nodes/ComfyUI-Impact-Pack && \
    python3 -m install 

RUN echo "########################################" && \
    echo "Init ComfyUI-Allor..." && \
    # copy config
    cp /opt/program/custom_nodes/ComfyUI-Allor/config.json /opt/program/ComfyUI/custom_nodes/ComfyUI-Allor/config.json

RUN echo "########################################"


# Expose port 8080 for sagemaker inference
EXPOSE 8080
ENTRYPOINT ["python3"]
CMD [ "serve" ]
HEALTHCHECK CMD curl -fs http://localhost:8080/ping || exit 1
